<?xml version="1.0" encoding="UTF-8"?>
<results title="runaway">
 <result pre="bottom-up perceptual information to these neural patterns using a forward-encoding" exact="model" post="of primary visual cortex (HMAX13). In this way, we"/>
 <result pre="(Meng = 76%, Mnov = 66%, t(29) = 2.44, p = 0.02; Fig. 1b inset). A linear mixed-effects" exact="model" post="revealed significant main effects of both run (β = 0.03, SE = 0.01,"/>
 <result pre="students (top left) and novices (top right), accompanied by the" exact="model" post="DM for the mechanical categories of the stimuli. Engineering"/>
 <result pre="the visual similarity analysis are shown, alongside the visual similarity" exact="model" post="DM produced by HMAX. Both groups show peak visual"/>
 <result pre="entirely data-driven; at no point was an a priori representational" exact="model" post="introduced. (This analysis is described in full detail in"/>
 <result pre="each participant were then correlated with a mechanical category information" exact="model" post="DM, as well as a visual similarity model DM"/>
 <result pre="category information model DM, as well as a visual similarity" exact="model" post="DM as a control analysis. The mechanical category DM"/>
 <result pre="be divided: cantilevers, trusses, and vertical loads. The visual similarity" exact="model" post="DM for the stimulus items was generated using the"/>
 <result pre="for the stimulus items was generated using the HMAX forward-encoding" exact="model" post="of primary visual cortex. Finally, we computed a summary"/>
 <result pre="showed a significant peak correlation with the mechanical category representation" exact="model" post="in a bilateral anterior vOT informational network (t(15) = 2.27, p = 0.038),"/>
 <result pre="the mechanical category representations cannot be accounted for by a" exact="model" post="of item-level visual similarity alone. As a descriptive visualization"/>
 <result pre="visual informational gradient peak representations (nor in the visual similarity" exact="model" post="representation itself). Fig. 5 Descriptive visualization showing that the"/>
 <result pre="from the mechanical category analysis. In contrast, the visual similarity" exact="model" post="and the peak informational networks from the visual similarity"/>
 <result pre="encounter a ceiling effect; Fig. 1), despite not receiving any" exact="feedback" post="about their task performance. This behavioral change is therefore"/>
 <result pre="that does not come out of the univariate general linear" exact="model" post="(GLM). This difference between an analysis of global signal"/>
 <result pre="whether the labeling was correct or incorrect based on the" exact="model" post="they had imagined during the fixation period, and indicate"/>
 <result pre="calculate beta-value estimates for each stimulus, an item-level univariate regression" exact="model" post="was computed for each functional run using the GLM."/>
 <result pre="To accomplish this, an explanatory variable was set up to" exact="model" post="the brain activity associated with each individual stimulus. Activity"/>
 <result pre="an unconfounded estimate of the BOLD signal. In order to" exact="model" post="this brain activity separately from the rest of the"/>
 <result pre="button press, a separate explanatory variable was set up to" exact="model" post="brain activity associated with the response period (4 s per"/>
 <result pre="correlations were calculated between each informational network DM and a" exact="model" post="DM representing the mechanical structure category for each stimulus"/>
 <result pre="neural activity patterns, we performed a control analysis using a" exact="model" post="of visual similarity between items in the stimulus set."/>
 <result pre="set. For this control analysis, we computed a visual similarity" exact="model" post="of the stimuli using a forward-encoding model of primary"/>
 <result pre="a visual similarity model of the stimuli using a forward-encoding" exact="model" post="of primary visual cortex (HMAX, C1 layer13). RSA was"/>
 <result pre="3, using the identical approach as for the mechanical category" exact="model" post="but this time targeting the visual similarity model. The"/>
 <result pre="showing the correlations between neural representations and the visual similarity" exact="model" post="for each group are displayed in Fig. 3, and"/>
 <result pre="the mechanical category information peaks and the mechanical and visual" exact="model" post="DMs in Fig. 5. (The mechanical and visual RSA"/>
 <result pre="of the Cognitive Neuroscience of Learning Lab at Dartmouth for" exact="feedback" post="on earlier versions of this manuscript. Author contributions J.S.C."/>
</results>
